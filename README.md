ğŸ  House Price Prediction

Predict house prices using ensemble learning and boosting models with advanced data preprocessing and feature engineering.

ğŸ”¹ Project Overview

This project implements multiple regression models to predict house prices, including:

Decision Tree

Random Forest

Gradient Boosting

XGBoost

Gradient Boosting achieved the best performance.

ğŸ”¹ Key Features

Handling missing data (median for numeric, 'None' for categorical)

Log transformation for skewed features and target variable

One-hot encoding of categorical variables

Hyperparameter tuning with GridSearchCV

ğŸ”¹ Model Evaluation
Model	RMSLE	MAE	RMSE	RÂ²
Gradient Boosting	0.0251	3586	4738	0.996
XGBoost	0.0443	5802	8275	0.989
Random Forest	0.0532	6617	12592	0.975
Linear Regression	0.0922	11345	17828	0.950
Decision Tree	0.1255	15938	25641	0.896
Dummy Regressor	0.3993	55616	80676	-0.032

Insight: Gradient Boosting is the most accurate; XGBoost offers faster training with competitive results.

ğŸ”¹ Feature Importance (Top 5)

OverallQual â€“ Overall material & finish

GrLivArea â€“ Above-grade living area

TotalBsmtSF â€“ Basement square footage

GarageCars â€“ Garage capacity

1stFlrSF â€“ First-floor area

ğŸ”¹ Limitations

Underestimates high-priced houses

Residuals show heteroscedasticity for expensive properties


ğŸ”¹ Conclusion

Gradient Boosting delivers the best predictions, balancing accuracy and interpretability. XGBoost is a faster alternative with slightly lower performance.
